{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 472 - Assignment 3\n",
    "\n",
    "### Bernard Claveau - 40065756 / Nicolas Eliopoulos - 40059378\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Bag-of-Words Classifier [(documentation)](#NB_BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NB_BOW:\n",
    "    \n",
    "    def __init__(self, *, filter=False):\n",
    "        self.ts = None\n",
    "        self.filter = filter\n",
    "        self.v = {}\n",
    "        self.p_yes = None\n",
    "        self.p_no = None\n",
    "        self.yes_prob = {}\n",
    "        self.no_prob = {}\n",
    "        \n",
    "        \n",
    "    def train(self, ts):\n",
    "        self.ts = ts\n",
    "        self.v = self.__build_vocab()\n",
    "        self.p_yes, self.p_no = self.__calculate_priors()\n",
    "        self.yes_prob, self.no_prob = self.__calculate_conditionals()\n",
    "        \n",
    "        \n",
    "    def predict(self, test):\n",
    "        prediction = []\n",
    "        ids = test.iloc[:, 0]\n",
    "        tweets = test.iloc[:, 1].str.lower()\n",
    "        labels = test.iloc[:, 2]\n",
    "        \n",
    "        for i in range(len(test)):\n",
    "            prediction.append((ids[i],) + self.__classify(tweets[i]) + (labels[i],))\n",
    "        return prediction\n",
    "       \n",
    "        \n",
    "    def __build_vocab(self):\n",
    "        self.ts.text = self.ts.text.str.lower()\n",
    "        v = {}\n",
    "\n",
    "        # build dict of words and their frequencies\n",
    "        for tweet in self.ts.text:\n",
    "            words = tweet.split()\n",
    "            for w in words:\n",
    "                if w in v:\n",
    "                    v[w] += 1\n",
    "                else:\n",
    "                    v[w] = 1\n",
    "        \n",
    "        if self.filter:\n",
    "            return { key:value for (key, value) in v.items() if value > 1}\n",
    "        return v\n",
    "    \n",
    "    \n",
    "    def __calculate_priors(self):\n",
    "        return self.ts.q1_label.value_counts()['yes'] / len(self.ts), self.ts.q1_label.value_counts()['no'] / len(self.ts)\n",
    "    \n",
    "    \n",
    "    def __calculate_conditionals(self):\n",
    "        yes_tweets = self.ts.loc[self.ts.q1_label == 'yes'].text\n",
    "        no_tweets = self.ts.loc[self.ts.q1_label == 'no'].text\n",
    "        \n",
    "        # word frequencies divided by class\n",
    "        yes_dict = {}\n",
    "        no_dict = {}\n",
    "        \n",
    "        # number of instances of words in each class\n",
    "        tw_yes = 0\n",
    "        tw_no = 0\n",
    "        \n",
    "        # conditional probabilities for each class\n",
    "        yes_prob = {}\n",
    "        no_prob = {}\n",
    "\n",
    "        for tweet in yes_tweets:\n",
    "            words = tweet.split()\n",
    "            for w in words:\n",
    "                tw_yes += 1\n",
    "                yes_dict[w] = 1 if w not in yes_dict else yes_dict[w] + 1\n",
    "                \n",
    "                # ensure that words found in 'yes' tweets but not 'no' tweets still have a conditional probability for 'no'\n",
    "                no_dict[w] = 0 if w not in no_dict else no_dict[w]\n",
    "\n",
    "        for tweet in no_tweets:\n",
    "            words = tweet.split()\n",
    "            for w in words:\n",
    "                tw_no += 1\n",
    "                no_dict[w] = 1 if w not in no_dict else no_dict[w] + 1\n",
    "                \n",
    "                # ensure that words found in 'no' tweets but not 'yes' tweets still have a conditional probability for 'yes'\n",
    "                yes_dict[w] = 0 if w not in yes_dict else yes_dict[w]\n",
    "        \n",
    "        for w in self.v:\n",
    "            yes_prob[w] = (yes_dict[w] + 0.01) / (tw_yes + 0.01*len(self.v))\n",
    "            no_prob[w] = (no_dict[w] + 0.01) / (tw_no + 0.01*len(self.v))\n",
    "            \n",
    "        return yes_prob, no_prob\n",
    "    \n",
    "    \n",
    "    def __classify(self, tweet):\n",
    "        yes, no = self.__score_yes(tweet), self.__score_no(tweet)\n",
    "        return ('yes', yes) if yes > no else ('no', no)\n",
    "        \n",
    "        \n",
    "    def __score_yes(self, tweet):\n",
    "        words = tweet.split()\n",
    "        score = math.log10(self.p_yes)\n",
    "        \n",
    "        for w in words:\n",
    "            score += math.log10(self.yes_prob[w]) if w in self.v else 0\n",
    "        return score\n",
    "\n",
    "    \n",
    "    def __score_no(self, tweet):\n",
    "        words = tweet.split()\n",
    "        score = math.log10(self.p_no)\n",
    "        \n",
    "        for w in words:\n",
    "            score += math.log10(self.no_prob[w]) if w in self.v else 0\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_files(prediction, name):\n",
    "    write_trace(prediction, name)\n",
    "    write_eval(prediction, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_trace(prediction, name):\n",
    "    with open('output/trace_' + name, 'w', encoding='utf-8') as f:\n",
    "        for i in range(len(prediction)):\n",
    "            result = 'correct' if prediction[i][1] == prediction[i][3] else 'wrong'\n",
    "            f.write(str(prediction[i][0]) + '  ' \n",
    "                    + prediction[i][1] + '  '\n",
    "                    + str(format(prediction[i][2], '.2e')) + '  '\n",
    "                    + prediction[i][3] + '  '\n",
    "                    + result + '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_eval(prediction, name):\n",
    "    with open('output/eval_' + name, 'w', encoding='utf-8') as f:\n",
    "        f.write(str(format(acc(prediction), '.4f')) + '\\r' \n",
    "                + str(format(precision(prediction)[0], '.4f')) + '  '\n",
    "                + str(format(precision(prediction)[1], '.4f')) + '\\r'\n",
    "                + str(format(recall(prediction)[0], '.4f')) + '  '\n",
    "                + str(format(recall(prediction)[1], '.4f')) + '\\r'\n",
    "                + str(format(f1(prediction)[0], '.4f')) + '  '\n",
    "                + str(format(f1(prediction)[1], '.4f')) + '\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(prediction):\n",
    "    acc = 1.1111111111  # TODO\n",
    "    return acc\n",
    "\n",
    "def precision(prediction):\n",
    "    yes_p, no_p = 2.222222222, 3.333333333  # TODO\n",
    "    return yes_p, no_p\n",
    "\n",
    "def recall(prediction):\n",
    "    yes_r, no_r = 4.444444444, 5.555555555  # TODO\n",
    "    return yes_r, no_r\n",
    "\n",
    "def f1(prediction):\n",
    "    yes_f, no_f = 6.6666666666, 7.777777777  # TODO\n",
    "    return yes_f, no_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = None\n",
    "\n",
    "with open('covid_training.tsv', 'r', encoding='utf-8') as f:\n",
    "    training_set = pd.read_csv(f, sep='\\t', encoding='utf-8').iloc[:, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = None\n",
    "\n",
    "with open('covid_test_public.tsv', 'r', encoding='utf-8') as f:\n",
    "    test_set = pd.read_csv(f, sep='\\t', encoding='utf-8', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Vocabulary - NB-BOW-OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_bow_ov = NB_BOW()\n",
    "\n",
    "nb_bow_ov.train(training_set)\n",
    "pred_ov = nb_bow_ov.predict(test_set)\n",
    "\n",
    "generate_output_files(pred_ov, 'NB-BOW-OV.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered Vocabulary - NB-BOW-FV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_bow_fv = NB_BOW(filter=True)\n",
    "\n",
    "nb_bow_fv.train(training_set)\n",
    "pred_fv = nb_bow_fv.predict(test_set)\n",
    "\n",
    "generate_output_files(pred_fv, 'NB-BOW-FV.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## NB_BOW\n",
    "\n",
    "### Fields\n",
    "\n",
    "- **ts** - the DataFrame of the training set with columns *tweet_id*, *text*, and *q1_label*\n",
    "- **filter** - whether or not to filter the vocabulary\n",
    "- **v** - the vocabulary of the model\n",
    "- **p_yes** - the prior of class **yes**\n",
    "- **p_no** - the prior of class **no**\n",
    "- **yes_prob** - a dict of the conditionals for class **yes**\n",
    "- **no_prob** - a dict of the conditionals for class **no**\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Public methods\n",
    "\n",
    "#### train\n",
    "\n",
    "- Trains the classifier with the given training set.\n",
    "\n",
    "#### predict\n",
    "\n",
    "- Predicts the classes of the given test set.\n",
    "- **Return:** list of tuples of the form (tweet_id, predicted_label, score_of_predicted_label, actual_label)\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Private methods\n",
    "\n",
    "#### build_vocab\n",
    "\n",
    "- Converts all tweets to lowercase.\n",
    "- Loops through all tweets and all words in each tweet (separated by whitespace) and adds each word to the dictionary or updates its frequency.\n",
    "- If **filter** is true, then words that appear only once are filtered out of the vocabulary.\n",
    "- **Return:** vocabulary (dict)\n",
    "\n",
    "#### calculate_priors\n",
    "\n",
    "- Calculates the prior probabilities of the classes **yes** and **no**.\n",
    "- **Return:** prior of **yes** (float), prior of **no** (float)\n",
    "\n",
    "#### calculate_conditionals\n",
    "\n",
    "- Calculates the conditional probabilties of each word in the vocabulary for both classes, using δ = 0.01 smoothing.\n",
    "- **Return:** conditionals given **yes** (dict), conditionals given **no** (dict)\n",
    "\n",
    "#### classify\n",
    "\n",
    "- Classifies a tweet as either **yes** or **no**.\n",
    "- **Return:** tuple of the form (predicted_label, score_of_predicited_label)\n",
    "\n",
    "#### score_yes\n",
    "\n",
    "- Calculates the score for **yes** of a tweet using log<sub>10</sub>.\n",
    "- **Returns:** score for **yes** (float)\n",
    "\n",
    "#### score_no\n",
    "\n",
    "- Calculates the score for **no** of a tweet using log<sub>10</sub>.\n",
    "- **Returns:** score for **no** (float)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
